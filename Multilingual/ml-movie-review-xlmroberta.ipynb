{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade numpy\n!pip install --upgrade SciPy\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T15:07:19.263169Z","iopub.execute_input":"2023-11-29T15:07:19.263785Z","iopub.status.idle":"2023-11-29T15:08:00.916729Z","shell.execute_reply.started":"2023-11-29T15:07:19.263751Z","shell.execute_reply":"2023-11-29T15:08:00.915535Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.24.3)\nCollecting numpy\n  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/64/41/284783f1014685201e447ea976e85fed0e351f5debbaf3ee6d7645521f1d/numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.24.3\n    Uninstalling numpy-1.24.3:\n      Successfully uninstalled numpy-1.24.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.2 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.11.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.11.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.11.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.11.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.11.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.11.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nnumba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.2 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.26.2 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.3 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.11.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.11.0 which is incompatible.\ntensorflow 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 1.26.2 which is incompatible.\ntensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\nwoodwork 0.26.0 requires numpy<1.25.0,>=1.22.0, but you have numpy 1.26.2 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.26.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.26.1\nRequirement already satisfied: SciPy in /opt/conda/lib/python3.10/site-packages (1.11.3)\nCollecting SciPy\n  Obtaining dependency information for SciPy from https://files.pythonhosted.org/packages/e0/9e/80e2205d138960a49caea391f3710600895dd8292b6868dc9aff7aa593f9/scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from SciPy) (1.26.1)\nDownloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: SciPy\n  Attempting uninstall: SciPy\n    Found existing installation: scipy 1.11.3\n    Uninstalling scipy-1.11.3:\n      Successfully uninstalled scipy-1.11.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.11.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.11.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.26.1 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\ntensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\nwoodwork 0.26.0 requires numpy<1.25.0,>=1.22.0, but you have numpy 1.26.1 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.26.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed SciPy-1.11.4\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, AdamW\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-29T15:08:09.283911Z","iopub.execute_input":"2023-11-29T15:08:09.284549Z","iopub.status.idle":"2023-11-29T15:08:09.289619Z","shell.execute_reply.started":"2023-11-29T15:08:09.284517Z","shell.execute_reply":"2023-11-29T15:08:09.288505Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/movie-reviews-dataset/test.tsv', sep='\\t')\ntest_df","metadata":{"execution":{"iopub.status.busy":"2023-11-29T15:08:27.903308Z","iopub.execute_input":"2023-11-29T15:08:27.903688Z","iopub.status.idle":"2023-11-29T15:08:29.299309Z","shell.execute_reply.started":"2023-11-29T15:08:27.903657Z","shell.execute_reply":"2023-11-29T15:08:29.298200Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"     lang label                                             review\n0      pl   neg  Bardzo intensywnie i długo zastanawiałem się, ...\n1      sk   pos  Režisér Richard Kelly, tvorca skvelého Donnieh...\n2      sk   pos  Stáva sa to pomerne často. Príprava filmu sa n...\n3      sk   neg  Tretí diel rebootovaného Star Treku od J. J. A...\n4      de   neg  „Spieglein, Spieglein an der Wand…“ heißt es i...\n...   ...   ...                                                ...\n9995   de   neg  Die Grundidee von »Before I Fall« (so der Orig...\n9996   pl   pos  Odkąd tylko Zack Snyder przestał mieć większy ...\n9997   fr   neg  Et bien sûr, comme on s'y attendait, le jeu Ou...\n9998   fr   pos  Est-ce l'un de ces cas typiques où la forme pr...\n9999   es   neg  Desastroso remake estadounidense del film fran...\n\n[10000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lang</th>\n      <th>label</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>pl</td>\n      <td>neg</td>\n      <td>Bardzo intensywnie i długo zastanawiałem się, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sk</td>\n      <td>pos</td>\n      <td>Režisér Richard Kelly, tvorca skvelého Donnieh...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sk</td>\n      <td>pos</td>\n      <td>Stáva sa to pomerne často. Príprava filmu sa n...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sk</td>\n      <td>neg</td>\n      <td>Tretí diel rebootovaného Star Treku od J. J. A...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>de</td>\n      <td>neg</td>\n      <td>„Spieglein, Spieglein an der Wand…“ heißt es i...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>de</td>\n      <td>neg</td>\n      <td>Die Grundidee von »Before I Fall« (so der Orig...</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>pl</td>\n      <td>pos</td>\n      <td>Odkąd tylko Zack Snyder przestał mieć większy ...</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>fr</td>\n      <td>neg</td>\n      <td>Et bien sûr, comme on s'y attendait, le jeu Ou...</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>fr</td>\n      <td>pos</td>\n      <td>Est-ce l'un de ces cas typiques où la forme pr...</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>es</td>\n      <td>neg</td>\n      <td>Desastroso remake estadounidense del film fran...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/movie-reviews-dataset/train.tsv', sep='\\t')\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2023-11-29T15:08:33.632870Z","iopub.execute_input":"2023-11-29T15:08:33.633283Z","iopub.status.idle":"2023-11-29T15:08:43.707461Z","shell.execute_reply.started":"2023-11-29T15:08:33.633253Z","shell.execute_reply":"2023-11-29T15:08:43.706489Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"      lang label                                             review\n0       de   pos  Einen Ausweg gibt es vielleicht für Daru (Vigg...\n1       pl   n\\a  Ouija to całkiem niezły reżyserski debiut Stil...\n2       pl   pos  Bardzo lubię kino niemieckie. Jest fenomenalne...\n3       pl   pos  Całkiem niedawno trafiłem na nie tak świeżą pr...\n4       cs   pos  V roce 1963, tedy v době, kdy se začalo mimo j...\n...    ...   ...                                                ...\n79847   pl   n\\a  Każdy z nas chciałby mieć życie usłane różami ...\n79848   pl   pos  Jaka młodość jest, wszyscy wiedzą – piękna, ra...\n79849   de   n\\a  Mit „Rückenwind“ hat Regisseur Jan Krüger im P...\n79850   pl   n\\a  Wysokobudżetowe ekranizacje gier to jest to, c...\n79851   pl   n\\a  Berlin Calling to trzeci film Hannesa Stöhra. ...\n\n[79852 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lang</th>\n      <th>label</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>de</td>\n      <td>pos</td>\n      <td>Einen Ausweg gibt es vielleicht für Daru (Vigg...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pl</td>\n      <td>n\\a</td>\n      <td>Ouija to całkiem niezły reżyserski debiut Stil...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pl</td>\n      <td>pos</td>\n      <td>Bardzo lubię kino niemieckie. Jest fenomenalne...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>pl</td>\n      <td>pos</td>\n      <td>Całkiem niedawno trafiłem na nie tak świeżą pr...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cs</td>\n      <td>pos</td>\n      <td>V roce 1963, tedy v době, kdy se začalo mimo j...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>79847</th>\n      <td>pl</td>\n      <td>n\\a</td>\n      <td>Każdy z nas chciałby mieć życie usłane różami ...</td>\n    </tr>\n    <tr>\n      <th>79848</th>\n      <td>pl</td>\n      <td>pos</td>\n      <td>Jaka młodość jest, wszyscy wiedzą – piękna, ra...</td>\n    </tr>\n    <tr>\n      <th>79849</th>\n      <td>de</td>\n      <td>n\\a</td>\n      <td>Mit „Rückenwind“ hat Regisseur Jan Krüger im P...</td>\n    </tr>\n    <tr>\n      <th>79850</th>\n      <td>pl</td>\n      <td>n\\a</td>\n      <td>Wysokobudżetowe ekranizacje gier to jest to, c...</td>\n    </tr>\n    <tr>\n      <th>79851</th>\n      <td>pl</td>\n      <td>n\\a</td>\n      <td>Berlin Calling to trzeci film Hannesa Stöhra. ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>79852 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import XLMRobertaTokenizer\n\ntokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n\ndef encode_data(data_df):\n    input_ids = []\n    attention_masks = []\n\n    for review in data_df['review']:\n        encoding = tokenizer.encode_plus(\n            review,\n            max_length=512,  # adjust based on your input size\n            add_special_tokens=True,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        input_ids.append(encoding['input_ids'])\n        attention_masks.append(encoding['attention_mask'])\n\n    input_ids = torch.cat(input_ids, dim=0)\n    attention_masks = torch.cat(attention_masks, dim=0)\n\n    return input_ids, attention_masks\n\ntrain_input_ids, train_attention_masks = encode_data(train_df)\ntest_input_ids, test_attention_masks = encode_data(test_df)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T15:08:48.251664Z","iopub.execute_input":"2023-11-29T15:08:48.252587Z","iopub.status.idle":"2023-11-29T15:19:19.076064Z","shell.execute_reply.started":"2023-11-29T15:08:48.252549Z","shell.execute_reply":"2023-11-29T15:19:19.075157Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11d2a5ff17e0427eb343bb0efa701555"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efc817328a23484e8b87ae8a9363dea4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd0ce5ee5c1f4033a5445726ef47c63a"}},"metadata":{}}]},{"cell_type":"code","source":"train_labels = torch.tensor([1 if label == 'pos' else 0 for label in train_df['label']])\ntest_labels = torch.tensor([1 if label == 'pos' else 0 for label in test_df['label']])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T15:19:31.020421Z","iopub.execute_input":"2023-11-29T15:19:31.020791Z","iopub.status.idle":"2023-11-29T15:19:31.077455Z","shell.execute_reply.started":"2023-11-29T15:19:31.020761Z","shell.execute_reply":"2023-11-29T15:19:31.076589Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\ntest_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T15:20:48.960124Z","iopub.execute_input":"2023-11-29T15:20:48.960883Z","iopub.status.idle":"2023-11-29T15:20:48.966087Z","shell.execute_reply.started":"2023-11-29T15:20:48.960836Z","shell.execute_reply":"2023-11-29T15:20:48.965059Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=2)  # 2 classes: pos, neg\noptimizer = AdamW(model.parameters(), lr=2e-5)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T15:20:51.845293Z","iopub.execute_input":"2023-11-29T15:20:51.845661Z","iopub.status.idle":"2023-11-29T15:20:59.161304Z","shell.execute_reply.started":"2023-11-29T15:20:51.845630Z","shell.execute_reply":"2023-11-29T15:20:59.160350Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1546f3b647c54f29b6d7083010af1c3d"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\nfor epoch in range(1):\n    model.train()\n    total_loss = 0.0\n\n    for batch in train_dataloader:\n        input_ids, attention_masks, labels = batch\n        input_ids, attention_masks, labels = input_ids.to(device), attention_masks.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()\n\n        loss.backward()\n        optimizer.step()\n\n    average_loss = total_loss / len(train_dataloader)\n    print(f'Epoch {epoch + 1}, Average Loss: {average_loss:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T15:20:59.162941Z","iopub.execute_input":"2023-11-29T15:20:59.163227Z","iopub.status.idle":"2023-11-29T16:34:46.859292Z","shell.execute_reply.started":"2023-11-29T15:20:59.163200Z","shell.execute_reply":"2023-11-29T16:34:46.858204Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1, Average Loss: 0.6836\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    correct_predictions = 0\n    total_samples = 0\n\n    for batch in test_dataloader:\n        input_ids, attention_masks, labels = batch\n        input_ids, attention_masks, labels = input_ids.to(device), attention_masks.to(device), labels.to(device)\n\n        outputs = model(input_ids, attention_mask=attention_masks)\n        predictions = torch.argmax(outputs.logits, dim=1)\n        correct_predictions += torch.sum(predictions == labels).item()\n        total_samples += labels.size(0)\n\n    accuracy = correct_predictions / total_samples\n    print(f'Test Accuracy: {accuracy:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T16:40:18.101193Z","iopub.execute_input":"2023-11-29T16:40:18.101518Z","iopub.status.idle":"2023-11-29T16:43:03.699138Z","shell.execute_reply.started":"2023-11-29T16:40:18.101480Z","shell.execute_reply":"2023-11-29T16:43:03.697589Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Test Accuracy: 0.5000\n","output_type":"stream"}]}]}