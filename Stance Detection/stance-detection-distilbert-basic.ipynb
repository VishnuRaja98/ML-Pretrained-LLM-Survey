{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3992718,"sourceType":"datasetVersion","datasetId":2369239}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-05T19:57:53.852887Z","iopub.execute_input":"2023-12-05T19:57:53.853175Z","iopub.status.idle":"2023-12-05T19:57:54.206304Z","shell.execute_reply.started":"2023-12-05T19:57:53.853133Z","shell.execute_reply":"2023-12-05T19:57:54.205369Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/stance-detection-dataset/fnc-1-master/scorer.py\n/kaggle/input/stance-detection-dataset/fnc-1-master/README.md\n/kaggle/input/stance-detection-dataset/fnc-1-master/train_stances.csv\n/kaggle/input/stance-detection-dataset/fnc-1-master/test_stances_unlabeled.csv\n/kaggle/input/stance-detection-dataset/fnc-1-master/train_bodies.csv\n/kaggle/input/stance-detection-dataset/fnc-1-master/competition_test_stances.csv\n/kaggle/input/stance-detection-dataset/fnc-1-master/train_stances.random.csv\n/kaggle/input/stance-detection-dataset/fnc-1-master/competition_test_bodies.csv\n/kaggle/input/stance-detection-dataset/fnc-1-master/competition_test_stances_unlabeled.csv\n/kaggle/input/stance-detection-dataset/fnc-1-master/test_bodies.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Importing stock ml libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn import metrics\nimport transformers\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import DistilBertModel, DistilBertTokenizer\n\n# Preparing for TPU usage\n# import torch_xla\n# import torch_xla.core.xla_model as xm\n# device = xm.xla_device()\n\n# # Setting up the device for GPU usage\nfrom torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:57:54.208231Z","iopub.execute_input":"2023-12-05T19:57:54.208707Z","iopub.status.idle":"2023-12-05T19:58:00.524926Z","shell.execute_reply.started":"2023-12-05T19:57:54.208670Z","shell.execute_reply":"2023-12-05T19:58:00.524069Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"#load data\ndf_body_train = pd.read_csv(\"/kaggle/input/stance-detection-dataset/fnc-1-master/train_bodies.csv\")\ndf_stance_train = pd.read_csv(\"/kaggle/input/stance-detection-dataset/fnc-1-master/train_stances.csv\")\ndf_body_test = pd.read_csv(\"/kaggle/input/stance-detection-dataset/fnc-1-master/competition_test_bodies.csv\")\ndf_stance_test = pd.read_csv(\"/kaggle/input/stance-detection-dataset/fnc-1-master/competition_test_stances.csv\")\n\n\n# merge the tables by Body ID\ntrain_df = pd.merge(df_body_train, df_stance_train, on='Body ID', how='inner')\ntest_df = pd.merge(df_body_test, df_stance_test, on='Body ID', how='inner')\n\n# null_counts_train = train_df.isnull().sum() #no nulls\n# null_counts_test = test_df.isnull().sum()  #no nulls\n\ntotal_rows_train = len(train_df)\ntotal_rows_test = len(test_df)\n\nunique_body_ids_train = train_df['Body ID'].nunique()\nunique_body_ids_test = test_df['Body ID'].nunique()\n\nprint(\"TRAIN: Total number of rows: \",total_rows_train,\", Unique Body IDs:\",unique_body_ids_train)\nprint(\"TEST: Total number of rows: \",total_rows_test,\", Unique Body IDs:\",unique_body_ids_test)\n\n# print(train_df.head())\n# print(test_df.head())\n\n# convert the last column i.e. the categorical column to a one hot encoded list. \ntrain_df['list'] = pd.get_dummies(train_df['Stance'],columns=train_df.columns).astype(int).values.tolist()\nnew_df_train = train_df[['articleBody','Headline', 'list']].copy()\n# Passing colums as train.columns so that the encoding is consistent among train and test\ntest_df['list'] = pd.get_dummies(test_df['Stance'],columns=train_df.columns).astype(int).values.tolist()\nnew_df_test = test_df[['articleBody','Headline', 'list']].copy()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:58:00.526046Z","iopub.execute_input":"2023-12-05T19:58:00.526487Z","iopub.status.idle":"2023-12-05T19:58:01.036460Z","shell.execute_reply.started":"2023-12-05T19:58:00.526459Z","shell.execute_reply":"2023-12-05T19:58:01.035511Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"TRAIN: Total number of rows:  49972 , Unique Body IDs: 1683\nTEST: Total number of rows:  25413 , Unique Body IDs: 904\n","output_type":"stream"}]},{"cell_type":"code","source":"new_df_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:58:01.039536Z","iopub.execute_input":"2023-12-05T19:58:01.040210Z","iopub.status.idle":"2023-12-05T19:58:01.056656Z","shell.execute_reply.started":"2023-12-05T19:58:01.040173Z","shell.execute_reply":"2023-12-05T19:58:01.055784Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                         articleBody  \\\n0  A small meteorite crashed into a wooded area i...   \n1  A small meteorite crashed into a wooded area i...   \n2  A small meteorite crashed into a wooded area i...   \n3  A small meteorite crashed into a wooded area i...   \n4  A small meteorite crashed into a wooded area i...   \n\n                                            Headline          list  \n0  Soldier shot, Parliament locked down after gun...  [0, 0, 0, 1]  \n1  Tourist dubbed ‘Spider Man’ after spider burro...  [0, 0, 0, 1]  \n2  Luke Somers 'killed in failed rescue attempt i...  [0, 0, 0, 1]  \n3   BREAKING: Soldier shot at War Memorial in Ottawa  [0, 0, 0, 1]  \n4  Giant 8ft 9in catfish weighing 19 stone caught...  [0, 0, 0, 1]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>articleBody</th>\n      <th>Headline</th>\n      <th>list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A small meteorite crashed into a wooded area i...</td>\n      <td>Soldier shot, Parliament locked down after gun...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A small meteorite crashed into a wooded area i...</td>\n      <td>Tourist dubbed ‘Spider Man’ after spider burro...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A small meteorite crashed into a wooded area i...</td>\n      <td>Luke Somers 'killed in failed rescue attempt i...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A small meteorite crashed into a wooded area i...</td>\n      <td>BREAKING: Soldier shot at War Memorial in Ottawa</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A small meteorite crashed into a wooded area i...</td>\n      <td>Giant 8ft 9in catfish weighing 19 stone caught...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"new_df_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:58:01.057778Z","iopub.execute_input":"2023-12-05T19:58:01.058062Z","iopub.status.idle":"2023-12-05T19:58:01.068914Z","shell.execute_reply.started":"2023-12-05T19:58:01.058035Z","shell.execute_reply":"2023-12-05T19:58:01.067990Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                         articleBody  \\\n0  Al-Sisi has denied Israeli reports stating tha...   \n1  Al-Sisi has denied Israeli reports stating tha...   \n2  Al-Sisi has denied Israeli reports stating tha...   \n3  Al-Sisi has denied Israeli reports stating tha...   \n4  Al-Sisi has denied Israeli reports stating tha...   \n\n                                            Headline          list  \n0  Apple installing safes in-store to protect gol...  [0, 0, 0, 1]  \n1  El-Sisi denies claims he'll give Sinai land to...  [1, 0, 0, 0]  \n2  Apple to keep gold Watch Editions in special i...  [0, 0, 0, 1]  \n3  Apple Stores to Keep Gold “Edition” Apple Watc...  [0, 0, 0, 1]  \n4  South Korean woman's hair 'eaten' by robot vac...  [0, 0, 0, 1]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>articleBody</th>\n      <th>Headline</th>\n      <th>list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n      <td>Apple installing safes in-store to protect gol...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n      <td>El-Sisi denies claims he'll give Sinai land to...</td>\n      <td>[1, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n      <td>Apple to keep gold Watch Editions in special i...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n      <td>Apple Stores to Keep Gold “Edition” Apple Watc...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n      <td>South Korean woman's hair 'eaten' by robot vac...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"new_df_train['articleBody'].apply(lambda x: len(str(x).split())).max()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:58:01.070034Z","iopub.execute_input":"2023-12-05T19:58:01.070322Z","iopub.status.idle":"2023-12-05T19:58:02.017201Z","shell.execute_reply.started":"2023-12-05T19:58:01.070298Z","shell.execute_reply":"2023-12-05T19:58:02.016330Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"4788"},"metadata":{}}]},{"cell_type":"code","source":"# Sections of config\n\n# Defining some key variables that will be used later on in the training\nMAX_LEN = 240\nTRAIN_BATCH_SIZE = 12\nVALID_BATCH_SIZE = 6\nEPOCHS = 4\nLEARNING_RATE = 1e-05\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:58:02.018407Z","iopub.execute_input":"2023-12-05T19:58:02.018739Z","iopub.status.idle":"2023-12-05T19:58:03.293194Z","shell.execute_reply.started":"2023-12-05T19:58:02.018689Z","shell.execute_reply":"2023-12-05T19:58:03.292279Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42020e672d6c4124adbf036012f19da3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f63624e645274631b750dd87913f91d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a95ec56cac334f6f9317881c6f0b9a73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe40469e84704310a17d22b2147520ab"}},"metadata":{}}]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.article_body = self.data[\"articleBody\"]\n        self.headline = self.data[\"Headline\"]\n        self.targets = self.data.list\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.article_body)\n\n    def __getitem__(self, index):\n        article_body = str(self.article_body[index])\n        article_body = \" \".join(article_body.split())\n        headline = str(self.headline[index])\n        headline = \" \".join(headline.split())\n\n\n        inputs = self.tokenizer(\n            article_body, \n            headline,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n#             return_token_type_ids=True,\n            truncation='only_first', \n            return_overflowing_tokens=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n#         token_type_ids = inputs[\"token_type_ids\"]\n\n\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n#             'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n        }","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:58:03.294375Z","iopub.execute_input":"2023-12-05T19:58:03.294666Z","iopub.status.idle":"2023-12-05T19:58:03.305408Z","shell.execute_reply.started":"2023-12-05T19:58:03.294638Z","shell.execute_reply":"2023-12-05T19:58:03.304126Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Creating the dataset and dataloader for the neural network\n\ntrain_dataset=new_df_train.sample(frac=1,random_state=200).reset_index(drop=True)\ntest_dataset=new_df_test.sample(frac=1,random_state=200).reset_index(drop=True)\n\n\n# print(\"FULL Dataset: {}\".format(new_df.shape))\nprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\nprint(\"TEST Dataset: {}\".format(test_dataset.shape))\n\ntraining_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\ntesting_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:58:03.306859Z","iopub.execute_input":"2023-12-05T19:58:03.307278Z","iopub.status.idle":"2023-12-05T19:58:03.336275Z","shell.execute_reply.started":"2023-12-05T19:58:03.307209Z","shell.execute_reply":"2023-12-05T19:58:03.335387Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"TRAIN Dataset: (49972, 3)\nTEST Dataset: (25413, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_params = {'batch_size': TRAIN_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntest_params = {'batch_size': VALID_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntraining_loader = DataLoader(training_set, **train_params)\ntesting_loader = DataLoader(testing_set, **test_params)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:58:03.339658Z","iopub.execute_input":"2023-12-05T19:58:03.339972Z","iopub.status.idle":"2023-12-05T19:58:03.345331Z","shell.execute_reply.started":"2023-12-05T19:58:03.339947Z","shell.execute_reply":"2023-12-05T19:58:03.344441Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class DistilBERTClass(torch.nn.Module):\n    def __init__(self):\n        super(DistilBERTClass, self).__init__()\n        self.l1 = DistilBertModel.from_pretrained('distilbert-base-uncased')\n#         Freeze the weights of the BERT layer\n        for param in self.l1.parameters():\n            param.requires_grad = False\n        self.pre_classifier = torch.nn.Linear(768, 768)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.classifier = torch.nn.Linear(768, 4)\n    \n    def forward(self, ids, mask):\n        output_1 = self.l1(input_ids=ids, attention_mask=mask)\n        hidden_state = output_1[0]\n        pooler = hidden_state[:, 0]\n        pooler = self.pre_classifier(pooler)\n        pooler = torch.nn.ReLU()(pooler)\n        pooler = self.dropout(pooler)\n        output = self.classifier(pooler)\n        return output\n\nmodel = DistilBERTClass()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:58:03.346613Z","iopub.execute_input":"2023-12-05T19:58:03.346952Z","iopub.status.idle":"2023-12-05T19:58:08.522105Z","shell.execute_reply.started":"2023-12-05T19:58:03.346927Z","shell.execute_reply":"2023-12-05T19:58:08.521157Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d740ea4db08b4fe89b7029058276ebfd"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DistilBERTClass(\n  (l1): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (classifier): Linear(in_features=768, out_features=4, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def loss_fn(outputs, targets):\n    return torch.nn.BCEWithLogitsLoss()(outputs, targets)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:58:08.523236Z","iopub.execute_input":"2023-12-05T19:58:08.523530Z","iopub.status.idle":"2023-12-05T19:58:08.528022Z","shell.execute_reply.started":"2023-12-05T19:58:08.523504Z","shell.execute_reply":"2023-12-05T19:58:08.526954Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:58:08.529213Z","iopub.execute_input":"2023-12-05T19:58:08.529551Z","iopub.status.idle":"2023-12-05T19:58:08.544110Z","shell.execute_reply.started":"2023-12-05T19:58:08.529525Z","shell.execute_reply":"2023-12-05T19:58:08.543377Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def train(epoch):\n    model.train()\n    for _,data in enumerate(training_loader, 0):\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n#         token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.float)\n\n        outputs = model(ids, mask)  #, token_type_ids)\n\n        optimizer.zero_grad()\n        loss = loss_fn(outputs, targets)\n        if _%5000==0:\n            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        \ndef validation(epoch):\n    model.eval()\n    fin_targets=[]\n    fin_outputs=[]\n    with torch.no_grad():\n        for _, data in enumerate(testing_loader, 0):\n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n#             token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n            outputs = model(ids, mask)#, token_type_ids)\n            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n    return fin_outputs, fin_targets","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:58:08.545295Z","iopub.execute_input":"2023-12-05T19:58:08.545883Z","iopub.status.idle":"2023-12-05T19:58:08.555457Z","shell.execute_reply.started":"2023-12-05T19:58:08.545856Z","shell.execute_reply":"2023-12-05T19:58:08.554656Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"accuracy_tracker = []\nf1_micro_tracker = []\nf1_macro_tracker = []\nprecision_tracker = []\nrecall_tracker = []\nmcc_tracker = []\nlogloss_tracker = []\nhammingloss_tracker = []\n\nfor epoch in range(EPOCHS):\n    print(\"Epoch \",epoch)\n    train(epoch)\n    outputs, targets = validation(epoch)\n    outputs = np.array(outputs) >= 0.5\n    accuracy = metrics.accuracy_score(targets, outputs)\n    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n    precision_score = metrics.precision_score(targets, outputs, average = 'samples', zero_division = 0)\n    recall_score = metrics.recall_score(targets, outputs, average = 'samples')\n    # MCC not supported for multiclass\n#     mcc_score = metrics.matthews_corrcoef(targets,outputs)\n    logloss_score = metrics.log_loss(targets, outputs)\n    hammingloss_score = metrics.hamming_loss(targets, outputs)\n    accuracy_tracker.append(accuracy)\n    f1_micro_tracker.append(f1_score_micro)\n    f1_macro_tracker.append(f1_score_macro)\n    precision_tracker.append(precision_score)\n    recall_tracker.append(recall_score)\n#     mcc_tracker.append(mcc_score)\n    logloss_tracker.append(logloss_score)\n    hammingloss_tracker.append(hammingloss_score)\n    print(f\"Accuracy Score = {accuracy}\")\n    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n    print(f\"F1 Score (Macro) = {f1_score_macro}\")\n    print(f\"Precision = {precision_score}\")\n    print(f\"Recall = {recall_score}\")\n#     print(f\"MCC = {mcc_score}\")\n    print(f\"LogLoss = {logloss_score}\")\n    print(f\"Hamming Loss = {hammingloss_score}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:58:08.556648Z","iopub.execute_input":"2023-12-05T19:58:08.556963Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch  0\nEpoch: 0, Loss:  0.6874668598175049\nAccuracy Score = 0.7220320308503522\nF1 Score (Micro) = 0.7220320308503523\nF1 Score (Macro) = 0.2096453544170742\nPrecision = 0.7220320308503522\nRecall = 0.7220320308503522\nLogLoss = 10.018981133306717\nHamming Loss = 0.13898398457482392\nEpoch  1\nEpoch: 1, Loss:  0.518197774887085\nAccuracy Score = 0.7220320308503522\nF1 Score (Micro) = 0.7220320308503523\nF1 Score (Macro) = 0.2096453544170742\nPrecision = 0.7220320308503522\nRecall = 0.7220320308503522\nLogLoss = 10.018981133306715\nHamming Loss = 0.13898398457482392\nEpoch  2\nEpoch: 2, Loss:  0.12313097715377808\nAccuracy Score = 0.7206154330460788\nF1 Score (Micro) = 0.7233193775179713\nF1 Score (Macro) = 0.21036180600556081\nPrecision = 0.7206154330460788\nRecall = 0.7206154330460788\nLogLoss = 9.81092515041169\nHamming Loss = 0.13782316137409986\nEpoch  3\nEpoch: 3, Loss:  0.23858904838562012\n","output_type":"stream"}]},{"cell_type":"code","source":"np.savetxt('stance_distilbert_loss_tracker.txt',[tensor.cpu().detach().numpy() for tensor in loss_tracker],delimiter=',')\nnp.savetxt('stance_distilbert_accuracy_tracker.txt',accuracy_tracker,delimiter=',')\nnp.savetxt('stance_distilbert_f1_micro_tracker.txt',f1_micro_tracker,delimiter=',')\nnp.savetxt('stance_distilbert_f1_macro_tracker.txt',f1_macro_tracker,delimiter=',')\n\nPkl_Filename = \"stance_detection_distilbert.pkl\"  \nimport pickle\nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(model, file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}